{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9198bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707288cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_kernel(kernel, k_width, k_height, scaling_factor = 1.0):\n",
    "    '''Zero-summing normalize kernel'''\n",
    "    \n",
    "    K_EPS = 1.0e-12\n",
    "    # positive and negative sum of kernel values\n",
    "    pos_range, neg_range = 0, 0\n",
    "    for i in range(k_width * k_height):\n",
    "        if abs(kernel[i]) < K_EPS:\n",
    "            kernel[i] = 0.0\n",
    "        if kernel[i] < 0:\n",
    "            neg_range += kernel[i]\n",
    "        else:\n",
    "            pos_range += kernel[i]\n",
    "    \n",
    "    # scaling factor for positive and negative range\n",
    "    pos_scale, neg_scale = pos_range, -neg_range\n",
    "    if abs(pos_range) >= K_EPS:\n",
    "        pos_scale = pos_range\n",
    "    else:\n",
    "        pos_sacle = 1.0\n",
    "    if abs(neg_range) >= K_EPS:\n",
    "        neg_scale = 1.0\n",
    "    else:\n",
    "        neg_scale = -neg_range\n",
    "        \n",
    "    pos_scale = scaling_factor / pos_scale\n",
    "    neg_scale = scaling_factor / neg_scale\n",
    "    \n",
    "    # scale kernel values for zero-summing kernel\n",
    "    for i in range(k_width * k_height):\n",
    "        if (not np.nan == kernel[i]):\n",
    "            kernel[i] *= pos_scale if kernel[i] >= 0 else neg_scale\n",
    "            \n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d134d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog(img, k_size, sigma_1, sigma_2):\n",
    "    '''Difference of Gaussian by subtracting kernel 1 and kernel 2'''\n",
    "    \n",
    "    k_width = k_height = k_size\n",
    "    x = y = (k_width - 1) // 2\n",
    "    kernel = np.zeros(k_width * k_height)\n",
    "    \n",
    "    # first gaussian kernal\n",
    "    if sigma_1 > 0:\n",
    "        co_1 = 1 / (2 * sigma_1 * sigma_1)\n",
    "        co_2 = 1 / (2 * np.pi * sigma_1 * sigma_1)\n",
    "        i = 0\n",
    "        for v in range(-y, y + 1):\n",
    "            for u in range(-x, x + 1):\n",
    "                kernel[i] = np.exp(-(u*u + v*v) * co_1) * co_2\n",
    "                i += 1\n",
    "    # unity kernel\n",
    "    else:\n",
    "        kernel[x + y * k_width] = 1.0\n",
    "    \n",
    "    # subtract second gaussian from kernel\n",
    "    if sigma_2 > 0:\n",
    "        co_1 = 1 / (2 * sigma_2 * sigma_2)\n",
    "        co_2 = 1 / (2 * np.pi * sigma_2 * sigma_2)\n",
    "        i = 0\n",
    "        for v in range(-y, y + 1):\n",
    "            for u in range(-x, x + 1):\n",
    "                kernel[i] -= np.exp(-(u*u + v*v) * co_1) * co_2\n",
    "                i += 1\n",
    "    # unity kernel\n",
    "    else:\n",
    "        kernel[x + y * k_width] -= 1.0\n",
    "    \n",
    "    # zero-normalize scling kernel with scaling factor 1.0\n",
    "    norm_kernel = normalize_kernel(kernel, k_width, k_height, scaling_factor = 1.0)\n",
    "    \n",
    "    # apply filter with norm_kernel\n",
    "    return cv2.filter2D(img, -1, norm_kernel.reshape(k_width, k_height))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88612f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate(img):\n",
    "    '''Negative of image'''\n",
    "    \n",
    "    return cv2.bitwise_not(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a265d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_black_white_indices(hist, tot_count, black_count, white_count):\n",
    "    '''Blacking and Whiting out indices same as color balance'''\n",
    "\n",
    "    black_ind = 0\n",
    "    white_ind = 255\n",
    "    co = 0\n",
    "    for i in range(len(hist)):\n",
    "        co += hist[i]\n",
    "        if co > black_count:\n",
    "            black_ind = i\n",
    "            break\n",
    "            \n",
    "    co = 0\n",
    "    for i in range(len(hist) - 1, -1, -1):\n",
    "        co += hist[i]\n",
    "        if co > (tot_count - white_count):\n",
    "            white_ind = i\n",
    "            break\n",
    "    \n",
    "    return [black_ind, white_ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3826c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_stretch(img, black_point, white_point):\n",
    "    '''Contrast stretch image with black and white cap'''\n",
    "    \n",
    "    tot_count = img.shape[0] * img.shape[1]\n",
    "    black_count = tot_count * black_point / 100\n",
    "    white_count= tot_count * white_point / 100\n",
    "    ch_hists = []\n",
    "    # calculate histogram for each channel\n",
    "    for ch in cv2.split(img):\n",
    "        ch_hists.append(cv2.calcHist([ch], [0], None, [256], (0, 256)).flatten().tolist())\n",
    "    \n",
    "    # get black and white percentage indices\n",
    "    black_white_indices = []\n",
    "    for hist in ch_hists:\n",
    "        black_white_indices.append(get_black_white_indices(hist, tot_count, black_count, white_count))\n",
    "        \n",
    "    stretch_map = np.zeros((3, 256), dtype = 'uint8')\n",
    "    \n",
    "    # stretch histogram \n",
    "    for curr_ch in range(len(black_white_indices)):\n",
    "        black_ind, white_ind = black_white_indices[curr_ch]\n",
    "        for i in range(stretch_map.shape[1]):\n",
    "            if i < black_ind:\n",
    "                stretch_map[curr_ch][i] = 0\n",
    "            else:\n",
    "                if i > white_ind:\n",
    "                    stretch_map[curr_ch][i] = 240\n",
    "                else:\n",
    "                    if (white_ind - black_ind) > 0:\n",
    "                        stretch_map[curr_ch][i] = round((i - black_ind) / (white_ind - black_ind)) * 255\n",
    "                    else:\n",
    "                        stretch_map[curr_ch][i] = 15\n",
    "    \n",
    "    # stretch image\n",
    "    ch_stretch = []\n",
    "    for i, ch in enumerate(cv2.split(img)):\n",
    "        ch_stretch.append(cv2.LUT(ch, stretch_map[i]))\n",
    "        \n",
    "    return cv2.merge(ch_stretch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc5d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_gaussian_blur(img, ksize, sigma):\n",
    "    '''Gussian blur using linear separable property of Gaussian distribution'''\n",
    "    \n",
    "    kernel_1d = cv2.getGaussianKernel(ksize, sigma)\n",
    "    return cv2.sepFilter2D(img, -1, kernel_1d, kernel_1d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcecc394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma(img, gamma_value):\n",
    "    '''Gamma correction of image'''\n",
    "    \n",
    "    i_gamma = 1 / gamma_value\n",
    "    lut = np.array([((i / 255) ** i_gamma) * 255 for i in np.arange(0, 256)], dtype = 'uint8')\n",
    "    return cv2.LUT(img, lut)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cfd38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_balance(img, low_per, high_per):\n",
    "    '''Contrast stretch image by histogram equilization with black and white cap'''\n",
    "    \n",
    "    tot_pix = img.shape[1] * img.shape[0]\n",
    "    # no.of pixels to black-out and white-out\n",
    "    low_count = tot_pix * low_per / 100\n",
    "    high_count = tot_pix * (100 - high_per) / 100\n",
    "    \n",
    "    cs_img = []\n",
    "    # for each channel, apply contrast-stretch\n",
    "    for ch in cv2.split(img):\n",
    "        # cummulative histogram sum of channel\n",
    "        cum_hist_sum = np.cumsum(cv2.calcHist([ch], [0], None, [256], (0, 256)))\n",
    "\n",
    "        # find indices for blacking and whiting out pixels\n",
    "        li, hi = np.searchsorted(cum_hist_sum, (low_count, high_count))\n",
    "        if (li == hi):\n",
    "            cs_img.append(ch)\n",
    "            continue\n",
    "        # lut with min-max normalization for [0-255] bins\n",
    "        lut = np.array([0 if i < li \n",
    "                        else (255 if i > hi else round((i - li) / (hi - li) * 255)) \n",
    "                        for i in np.arange(0, 256)], dtype = 'uint8')\n",
    "        # constrast-stretch channel\n",
    "        cs_ch = cv2.LUT(ch, lut)\n",
    "        cs_img.append(cs_ch)\n",
    "        \n",
    "    return cv2.merge(cs_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e944b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiteboard_enhance(img):\n",
    "    '''Enhance Whiteboard image'''\n",
    "\n",
    "    # parameters for enhancing functions\n",
    "    dog_k_size, dog_sigma_1, dog_sigma_2 = 15, 100, 0\n",
    "    cs_black_per, cs_white_per = 2, 99.5\n",
    "    gauss_k_size, gauss_sigma = 3, 1\n",
    "    gamma_value = 1.1\n",
    "    cb_black_per, cb_white_per = 2, 1\n",
    "\n",
    "    # Difference of Gaussian (DoG)\n",
    "    dog_img = dog(img, dog_k_size, dog_sigma_1, dog_sigma_2)\n",
    "    # Negative of image\n",
    "    negative_img = negate(dog_img)\n",
    "    # Contrast Stretch (CS)\n",
    "    contrast_stretch_img = contrast_stretch(negative_img, cs_black_per, cs_white_per)\n",
    "    # Gaussian Blur\n",
    "    blur_img = fast_gaussian_blur(contrast_stretch_img, gauss_k_size, gauss_sigma)\n",
    "    # Gamma Correction\n",
    "    gamma_img = gamma(blur_img, gamma_value)\n",
    "    # Color Balance (CB) (also Contrast Stretch)\n",
    "    color_balanced_img = color_balance(gamma_img, cb_black_per, cb_white_per)\n",
    "\n",
    "    return color_balanced_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48cfef1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00812e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-61a337272ce6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0menhanced_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhiteboard_enhance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menhanced_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-153e2705654f>\u001b[0m in \u001b[0;36mwhiteboard_enhance\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Difference of Gaussian (DoG)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdog_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdog_k_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdog_sigma_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdog_sigma_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Negative of image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mnegative_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnegate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdog_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d4f9091765dd>\u001b[0m in \u001b[0;36mdog\u001b[1;34m(img, k_size, sigma_1, sigma_2)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# apply filter with norm_kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_kernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if (cap.isOpened() == False): \n",
    "  print(\"Unable to read camera feed\")    \n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "while(True):\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "  if ret == True:\n",
    "    \n",
    "    out.write(frame)\n",
    "    enhanced_img = whiteboard_enhance(frame)\n",
    "\n",
    "    cv2.imshow('frame',enhanced_img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "  else:\n",
    "    break  \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
